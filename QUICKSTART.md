# Quick Reference: 4-Band Satellite Image Support\n\n## Installation\n\n```bash\npip install -r requirements.txt\n# Includes: rasterio for TIFF support\n```\n\n## File Format Requirements\n\n### 3-Band RGB Images\n- **Format**: `.jpg`, `.jpeg`, `.png`\n- **Channels**: 3 (Red, Green, Blue)\n- **Bit depth**: 8-bit\n- **Size**: Any (will be resized to 256x256)\n\n### 4-Band TIFF Images  \n- **Format**: `.tif`, `.tiff`\n- **Channels**: 4 (Red, Green, Blue, Near-Infrared)\n- **Bit depth**: 8-bit or 16-bit (auto-normalized)\n- **Size**: Any (will be resized to 256x256)\n\n## Quick Start Commands\n\n### Training on 4-Band Data\n\n```bash\n# Step 1: Organize your data\ndata/\n‚îú‚îÄ‚îÄ train_coco.json      # COCO annotations\n‚îú‚îÄ‚îÄ train_images/        # TIFF files (4-band)\n‚îú‚îÄ‚îÄ val_coco.json\n‚îî‚îÄ‚îÄ val_images/          # TIFF files (4-band)\n\n# Step 2: Train (auto-detects format)\npython train.py --device cuda --num_episodes 5000\n\n# Expected output:\n# ‚úÖ Detected 4-band images\n# Creating model with 4-band input...\n# Training 5000 episodes...\n```\n\n### Single Image Inference (4-Band)\n\n```bash\npython inference.py --mode single \\\n  --model_path checkpoints/best_model.pth \\\n  --support_img sat1.tif sat2.tif sat3.tif \\\n  --query_image query.tif \\\n  --device cuda\n```\n\n### Batch Inference (4-Band)\n\n```bash\npython inference.py --mode batch \\\n  --model_path checkpoints/best_model.pth \\\n  --support_img sat1.tif sat2.tif \\\n  --query_dir ./test_images/ \\\n  --output_csv results.csv \\\n  --device cuda\n```\n\n### RGB Images (3-Band)\n\n```bash\n# Training\npython train.py --device cuda --num_episodes 5000\n# Auto-detects 3-band JPG/PNG format\n\n# Inference\npython inference.py --mode single \\\n  --model_path checkpoints/best_model.pth \\\n  --support_img photo1.jpg photo2.jpg photo3.jpg \\\n  --query_image photo_query.jpg \\\n  --device cuda\n```\n\n## Tensor Shapes Reference\n\n```python\n# Input tensors\nsupport_images: torch.Size([10, 4, 256, 256])  # [N*K, C, H, W]\nquery_images: torch.Size([10, 4, 256, 256])    # [Q, C, H, W]\n\n# After backbone\nfeatures: torch.Size([10, 2048, 8, 8])  # [B, feat_dim, H/32, W/32]\n\n# After embedding\nembedding: torch.Size([10, 512, 8, 8])  # [B, embed_dim, H/32, W/32]\n\n# ROI pooling\nroi_features: torch.Size([10, 512, 7, 7])  # [boxes, C, pool_size, pool_size]\n\n# Detection head\ndet_features: torch.Size([10, 512])  # [boxes, hidden_dim]\n\n# Output\nboxes: torch.Size([N_det, 4])      # [x, y, w, h]\nscores: torch.Size([N_det])        # confidence\nclasses: torch.Size([N_det])       # class index\n```\n\n## Configuration Parameters\n\n```python\n# config.py\n\n# Image sizes\nIMAGE_SIZE = 256\n\n# Supported formats\nALLOWED_FORMATS = ['.jpg', '.jpeg', '.png', '.tif', '.tiff']\nALLOWED_CHANNELS = [3, 4]\n\n# Normalization\nIMAGE_MEAN_3BAND = [0.485, 0.456, 0.406]\nIMAGE_STD_3BAND = [0.229, 0.224, 0.225]\n\nIMAGE_MEAN_4BAND = [0.485, 0.456, 0.406, 0.406]  # RGBN\nIMAGE_STD_4BAND = [0.229, 0.224, 0.225, 0.225]\n\n# Few-shot parameters\nN_WAY = 5          # classes per episode\nK_SHOT = 2         # support images per class\nQUERY_SAMPLES = 10 # query images per class\n\n# Training\nBATCH_SIZE = 1     # episodes per batch\nNUM_EPISODES = 10000\nLEARNING_RATE = 1e-4\n```\n\n## Error Messages & Solutions\n\n### Error: \"Channel mismatch\"\n```\nChannel mismatch: support images have 3 channels \nbut query image has 4 channels.\n```\n**Solution**: Ensure all images in an episode have the same number of bands\n```python\n# ‚úÖ Correct\nsupport_imgs = ['sat1.tif', 'sat2.tif']  # All 4-band\nquery_img = 'sat3.tif'                    # 4-band\n\n# ‚ùå Wrong\nsupport_imgs = ['photo.jpg', 'sat.tif']  # Mixed: 3-band + 4-band\n```\n\n### Error: \"Unsupported number of channels\"\n**Solution**: Only 3-band (RGB) and 4-band (RGBN) supported\n\n### Error: \"TIF must have 4 bands\"\n**Solution**: TIFF files must have exactly 4 bands for this implementation\n\n### Error: \"Only JPG/PNG allowed\"\n**Solution**: Use correct file extensions (`.jpg`, `.png`, `.tif`)\n\n## Python API Usage\n\n```python\nfrom inference import FSODInference\n\n# Initialize\ninferencer = FSODInference('checkpoints/best_model.pth', device='cuda')\n\n# Prepare support set (auto-detects 3 or 4 bands)\nsupport_set = [\n    {'image_path': 'satellite1.tif', 'class_name': 'building'},\n    {'image_path': 'satellite2.tif', 'class_name': 'building'},\n]\n\n# Single image detection\ndetections = inferencer.detect(\n    support_set,\n    'satellite_query.tif',\n    score_threshold=0.3,\n    nms_threshold=0.4\n)\n\nfor det in detections:\n    x_min, y_min, x_max, y_max = det['bbox']\n    score = det['similarity_score']\n    class_name = det['class_name']\n    print(f\"{class_name} at [{x_min:.0f}, {y_min:.0f}] - {score:.3f}\")\n```\n\n## Data Format: COCO JSON\n\n```json\n{\n  \"images\": [\n    {\n      \"id\": 1,\n      \"file_name\": \"satellite_001.tif\",\n      \"height\": 1024,\n      \"width\": 1024\n    }\n  ],\n  \"annotations\": [\n    {\n      \"id\": 1,\n      \"image_id\": 1,\n      \"category_id\": 1,\n      \"bbox\": [x, y, width, height],\n      \"area\": width * height,\n      \"iscrowd\": 0\n    }\n  ],\n  \"categories\": [\n    {\"id\": 1, \"name\": \"building\"},\n    {\"id\": 2, \"name\": \"road\"}\n  ]\n}\n```\n\n## Model Checkpoints\n\n```bash\n# Training saves to checkpoints/\ncheckpoints/\n‚îú‚îÄ‚îÄ checkpoint_episode_1000.pth  # Regular checkpoints\n‚îú‚îÄ‚îÄ best_model.pth               # Best validation mAP\n‚îî‚îÄ‚îÄ final_model.pth              # After all episodes\n\n# Load for inference\npython inference.py ... --model_path checkpoints/best_model.pth\n```\n\n## Performance Tips\n\n1. **For 4-band satellite data**:\n   - Use at least 2000 training episodes\n   - Normalize NIR band separately if needed\n   - Consider fine-tuning from 3-band pretrained model\n\n2. **Memory optimization**:\n   - Default IMAGE_SIZE=256 fits in 4GB GPU\n   - Reduce to 128 for 2GB GPUs\n   - Increase to 512 for 16GB+ GPUs\n\n3. **Accuracy improvement**:\n   - Balanced dataset across classes\n   - At least 5-10 samples per class for k-shot\n   - Data augmentation handled automatically\n\n## Supported Hardware\n\n- **GPU**: Any CUDA-capable GPU (tested on RTX 2080, 3080, A100)\n- **CPU**: Supported but ~50-100x slower\n- **Memory**: 4GB minimum for training, 2GB for inference\n\n## Docker Support\n\n```bash\n# Build Docker image with TIFF support\ndocker build -t fsod:4band -f Dockerfile .\n\n# Run container\ndocker run --gpus all -v $(pwd):/workspace fsod:4band \\\n  python train.py --device cuda\n```\n\n## Testing Your Setup\n\n```bash\n# Test imports\npython3 -c \"import rasterio; print('‚úì rasterio OK')\"\npython3 -c \"import torch; print('‚úì torch OK')\"\npython3 -c \"from utils.data_loader import _load_image_from_path; print('‚úì data loader OK')\"\n\n# Test model creation\npython3 -c \"from models.detector import FSODDetector; m = FSODDetector(input_channels=4); print('‚úì 4-band model OK')\"\n```\n\n## Common Workflows\n\n### Workflow 1: Train & Inference with 4-Band\n```bash\n# 1. Train\npython train.py --device cuda --num_episodes 3000\n\n# 2. Inference\npython inference.py --mode batch \\\n  --model_path checkpoints/best_model.pth \\\n  --support_img sat1.tif sat2.tif \\\n  --query_dir test_data/ --device cuda\n```\n\n### Workflow 2: Load Pretrained 3-Band, Test on 4-Band\n```bash\n# Model will auto-adapt 4th channel from RGB weights\npython inference.py --mode single \\\n  --model_path pretrained_rgb_model.pth \\\n  --support_img sat1.tif sat2.tif \\\n  --query_image query.tif --device cuda\n```\n\n### Workflow 3: Fine-tune on 4-Band Data\n```bash\n# Load existing model and continue training\npython train.py --device cuda --num_episodes 1000 --pretrained\n```\n\n## Documentation Files\n\n- **MULTIBAND_GUIDE.md**: Comprehensive technical guide\n- **IMPLEMENTATION_SUMMARY.md**: What was changed and why\n- **PIPELINE_DIAGRAM.md**: Visual data flow diagrams\n- **QUICKSTART.md**: This file - quick reference\n\n---\n\n**Ready to use with 4-band satellite imagery!** üõ∞Ô∏è\n"